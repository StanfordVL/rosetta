# Running Experiments

This document explains how to run experiments using the Rosetta framework.

## Entry Point and Workflow

The experiment pipeline processes feedback data and generates reward functions. The entry point is `rosetta/run_exp/main.py`, which handles the following workflow:

1. Converting CSV/JSONL feedback files to the required format
2. Generating configurations based on the feedback
3. Generating reward functions based on configs
4. Generating train_sbatch.sh
5. Run train_sbatch.sh to train the policy

## Input

### Input Format

The input CSV file should contain the following columns:

| Column | Description |
|--------|-------------|
| Timestamp | Submission timestamp (can be empty) |
| Score | Score for the video (can be empty) |
| What's your name? | Annotator identifier (`annot_id`) |
| Which video are you giving feedback for? | Video name, used for `prev_uid` |
| Describe the video | Description of the video |
| Give feedback | Natural language feedback, used for `uid-feedback` |

These columns are processed to extract key information:
- `annot_id`: Identifies the person giving feedback
- `prev_uid`: Identifies the previous reward run (extracted from video name)
- `uid-feedback`: Unique identifier generated by hashing the feedback content
- `env_id`: Environment identifier extracted from the video name

### Command-Line Parameters

```
python -m rosetta.run_exp.main [PARAMETERS]
```

| Parameter | Description | Default | Example Usage |
|-----------|-------------|---------|---------------|
| `--source_file_path` | Path to load source CSV/JSONL file | `test.csv` | `--source_file_path ./feedback.csv` |
| `--jsonl_output_path` | Path to save JSONL output | `output.jsonl` | `--jsonl_output_path ./output.jsonl` |
| `--config_dirs_path` | Path to configuration directories | `exp/configs/` | `--config_dirs_path ./exp/configs` |
| `--result_dirs_path` | Path to results directories | `exp/results/` | `--result_dirs_path ./exp/results` |
| `--dry_run` | Run without submitting jobs | `False` | `--dry_run` |
| `--num_workers` | Number of worker processes | `4` | `--num_workers 8` |
| `--short_prompt_design` | Short prompt design | `rosetta_sh` | `--short_prompt_design custom_sh` |
| `--long_prompt_design` | Long prompt design | `rosetta_lh` | `--long_prompt_design custom_lh` |
| `--num_gen` | Number of rewards to generate | `1` | `--num_gen 3` |
| `--chosen_variants` | Specified indices of reward generation | `[]` | `--chosen_variants 0 2` |
| `--config_yaml` | Path to YAML configuration file | `None` | `--config_yaml ./config.yaml` |

### Other Examples 

Basic usage with a CSV feedback file:
```bash
python -m rosetta.run_exp.main --source_file_path ./feedback.csv --config_dirs_path ./exp/configs --result_dirs_path ./exp/results
```

Using a YAML configuration file (overrides command line arguments):
```bash
python -m rosetta.run_exp.main --config_yaml ./config.yaml
```

You can refer to "rosetta/demo/demo.yml" for an example of a configuration file.

## Output

The pipeline generates two main types of output directories:

### 1. Configuration Directories

Configuration files are generated in the specified `config_dirs_path` with the following naming pattern:

```
{annot_id}-{env_id}-{prev_uid}-{uid-feedback}
```

#### Example Configuration Directory:

```
exp/configs/demo-SphereAndBins-4ebb1fc87b6b0ebf-f4ec0d1425f99ff7/
└── exp_config.json
```

#### Example `exp_config.json`:

```json
{
    "annotator_name": "demo",
    "video_name": "-SphereAndBins-4ebb1fc87b6b0ebf",
    "feedback": "Slow it down and put it in the other bin.",
    "description": "",
    "annotator_id": "demo",
    "env_id": "SphereAndBins",
    "prev_uid": "4ebb1fc87b6b0ebf",
    "uid_feedback": "f4ec0d1425f99ff7"
}
```

### 2. Result Directories

Result files are generated in the specified `result_dirs_path` with the following naming pattern:

```
{annot_id}-{env_id}-{prev_uid}-{uid-feedback}-{uid-reward}
```

Where `uid-reward` is a unique identifier generated by hashing the reward content.

#### Files Generated in Result Directories:

```
exp/results/demo-SphereAndBins-4ebb1fc87b6b0ebf-f4ec0d1425f99ff7-32e3aa0e9c221199/
├── default_training_config.json  # Default configuration for training
├── exp_config.json               # Experiment configuration details
├── grounding_rst.json            # Grounding results from the feedback
├── reward.json                   # Generated reward function
└── train_sbatch.sh               # Batch script for training the policy
```

#### Example Result `exp_config.json`:

```json
{
    "annotator_name": "demo",
    "video_name": "-SphereAndBins-4ebb1fc87b6b0ebf",
    "feedback": "Slow it down and put it in the other bin.",
    "description": "",
    "annotator_id": "demo",
    "env_id": "SphereAndBins",
    "prev_uid": "4ebb1fc87b6b0ebf",
    "uid_feedback": "f4ec0d1425f99ff7",
    "uid_reward": "32e3aa0e9c221199",
    "stages": null,
    "round_hash": "7313d42b42afa433",
    "backup_folder": "rosetta/reward_backup/demo-SphereAndBins-4ebb1fc87b6b0ebf-f4ec0d1425f99ff7_gen8",
    "reward_variants": [0],
    "rounds": [0]
}
```

## Using the Generated Files

### Training with Generated Files

After the reward generation process completes, you can use the generated files to train your policy:

1. Navigate to the results directory that contains the generated files
2. Execute the training batch script:

```bash
cd exp/results/demo-SphereAndBins-4ebb1fc87b6b0ebf-f4ec0d1425f99ff7-32e3aa0e9c221199/
bash train_sbatch.sh
```

The `train_sbatch.sh` script contains all the necessary commands to train a policy using the generated reward function, eliminating the need for manual configuration.

### Querying History and Visualizing Results

To visualize the reward generation results and access related videos, use the `query_history_videos.py` script:

```bash
python -m rosetta.run_exp.query_history_videos --config_dirs_path ./exp/configs --result_dirs_path ./exp/results --save_path ./history_videos --num_ancestors 3
```

#### Parameters:

| Parameter | Description | Example Usage |
|-----------|-------------|---------------|
| `--config_dirs_path` | Path to configuration directories | `--config_dirs_path ./exp/configs` |
| `--result_dirs_path` | Path to results directories | `--result_dirs_path ./exp/results` |
| `--save_path` | Path to save history videos and feedback | `--save_path ./history_videos` |
| `--num_ancestors` | Number of ancestors to include in history | `--num_ancestors 3` |

#### Output Structure:

The script organizes videos and feedback in the following structure:

```
./history_videos/demo-SphereAndBins-4ebb1fc87b6b0ebf-f4ec0d1425f99ff7/
├── video_3.mp4                     # Oldest video in history
├── your_feedback_on_video_3.txt    # Feedback for the oldest video
├── video_2.mp4                     # Previous iteration video
├── your_feedback_on_video_2.txt    # Feedback for previous video
├── video_1.mp4                     # Most recent video
├── your_feedback_on_video_1.txt    # Feedback for most recent video
└── options-to-choose-from/         # Directory containing result videos
    ├── option1.mp4                 # Result video from variant 1
    ├── option2.mp4                 # Result video from variant 2
    └── ...
```

This organization makes it easy to trace the feedback history and see how it affected the generated rewards across iterations.

## Usage Examples

### Using Multiple Workers

For parallel processing, increase the number of workers:

```bash
python -m rosetta.run_exp.main --source_file_path ./feedback.csv --num_workers 8
```

### Dry Run Mode

Just generate reward function and do not submit training scripts:

```bash
python -m rosetta.run_exp.main --source_file_path ./feedback.csv --dry_run
```

### Multiple Reward Generations

To generate multiple reward variants:

```bash
python -m rosetta.run_exp.main --source_file_path ./feedback.csv --num_gen 3
```

### Selecting Specific Variants

To run only specific variants:
Rosetta will normally generate 0-5 variants, the last one is the most completed version.

```bash
python -m rosetta.run_exp.main --source_file_path ./feedback.csv --chosen_variants 0 2 
```